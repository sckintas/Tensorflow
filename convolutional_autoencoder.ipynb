{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 47s 193ms/step - loss: 0.0238 - val_loss: 0.0021\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 53s 225ms/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 58s 245ms/step - loss: 8.4938e-04 - val_loss: 7.5190e-04\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 51s 215ms/step - loss: 6.4192e-04 - val_loss: 5.5063e-04\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 50s 214ms/step - loss: 5.1788e-04 - val_loss: 4.6813e-04\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 54s 230ms/step - loss: 4.4026e-04 - val_loss: 4.3685e-04\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 47s 199ms/step - loss: 3.8804e-04 - val_loss: 3.6741e-04\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 51s 215ms/step - loss: 3.5264e-04 - val_loss: 4.0017e-04\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 44s 187ms/step - loss: 3.2586e-04 - val_loss: 3.0266e-04\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 44s 189ms/step - loss: 2.9761e-04 - val_loss: 2.7656e-04\n",
      "220/313 [====================>.........] - ETA: 1s"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def autoencoder(input_shape=(28, 28, 1),\n",
    "                n_filters=[1, 10, 10, 10],\n",
    "                filter_sizes=[3, 3, 3, 3],\n",
    "                corruption=False):\n",
    "    \"\"\"\n",
    "    Build a deep denoising autoencoder with tied weights.\n",
    "    \"\"\"\n",
    "    # Input Layer\n",
    "    input_img = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Optionally apply noise to the input images (Denoising Autoencoder)\n",
    "    if corruption:\n",
    "        input_img_corrupted = tf.keras.layers.GaussianNoise(stddev=0.5)(input_img)\n",
    "        current_input = input_img_corrupted\n",
    "    else:\n",
    "        current_input = input_img\n",
    "\n",
    "    # Encoder\n",
    "    encoder_layers = []\n",
    "    for n_filters, filter_size in zip(n_filters[1:], filter_sizes):\n",
    "        conv = tf.keras.layers.Conv2D(n_filters, (filter_size, filter_size), activation='linear', padding='same')(current_input)\n",
    "        act = tf.keras.layers.LeakyReLU()(conv)\n",
    "        current_input = act\n",
    "        encoder_layers.append(current_input)\n",
    "    \n",
    "    # Latent Representation\n",
    "    z = current_input\n",
    "    \n",
    "    # Decoder\n",
    "    for i, layer in enumerate(encoder_layers[::-1]):\n",
    "        n_filters = layer.get_shape().as_list()[-1]\n",
    "        if i == 0:\n",
    "            upsample = tf.keras.layers.Conv2DTranspose(n_filters, (filter_sizes[-1], filter_sizes[-1]), activation='linear', padding='same')(z)\n",
    "        else:\n",
    "            upsample = tf.keras.layers.Conv2DTranspose(n_filters, (filter_sizes[-(i+1)], filter_sizes[-(i+1)]), activation='linear', padding='same')(current_input)\n",
    "        act = tf.keras.layers.LeakyReLU()(upsample)\n",
    "        current_input = act\n",
    "    \n",
    "    # Output Layer (Reconstruction)\n",
    "    decoded = tf.keras.layers.Conv2D(input_shape[-1], (3, 3), activation='sigmoid', padding='same')(current_input)\n",
    "    \n",
    "    # Autoencoder Model\n",
    "    autoencoder_model = tf.keras.Model(inputs=input_img, outputs=decoded)\n",
    "    \n",
    "    # Compile the model\n",
    "    autoencoder_model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder_model\n",
    "\n",
    "def test_mnist():\n",
    "    \"\"\"\n",
    "    Test the convolutional autoencoder using MNIST dataset.\n",
    "    \"\"\"\n",
    "    # Load MNIST dataset\n",
    "    (x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Reshape the data to have channels\n",
    "    x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "    x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "    \n",
    "    # Create the Autoencoder model\n",
    "    autoencoder_model = autoencoder()\n",
    "    \n",
    "    # Train the model\n",
    "    autoencoder_model.fit(x_train, x_train, epochs=10, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n",
    "    \n",
    "    # Test the trained model\n",
    "    decoded_imgs = autoencoder_model.predict(x_test)\n",
    "    \n",
    "    # Plot the reconstructions\n",
    "    n = 10  # Number of digits to display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # Display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # Display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e244d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
